\documentclass{report}

\input{../template/preamble}
\input{../template/macros}
\input{../template/letterfonts}

\title{\Huge{Numerical Analysis}\\Semester 4}
\author{}
\date{}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak

\chapter{Interpolation}

\section{Linear Interpolation}

\begin{minipage}{0.4\linewidth}
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
					legend pos=outer north east,
					axis lines = box,
					xlabel = $x$,
					ylabel = $f(x)$,
					variable = t,
					trig format plots = rad,
					axis x line=bottom,
					axis y line=left,
					xmin=0,xmax=5.5,
					ymin=0,ymax=3.9,
				]

				\addplot[
					color=blue,
				]
				coordinates {
						(0,0)(1,2)(2,3)(3,1)(4,3)(5,3.5)
					};
				\addplot[
					color=red,
					only marks,
					mark=*,
				]
				coordinates {
						(0,0)(1,2)(2,3)(3,1)(4,3)(5,3.5)
					};

			\end{axis}
		\end{tikzpicture}
	\end{figure}
\end{minipage}
\hfill
\begin{minipage}{0.4\linewidth}
	\begin{tabular}{l|l}
		$x$ & $f(x)$ \\
		\hline
		0   & 0      \\
		1   & 2      \\
		2   & 3      \\
		3   & 1      \\
		4   & 3      \\
		5   & 3.5    \\
	\end{tabular}
\end{minipage}

Linear interpolation is just drawing lines between the data points.
\dfn{Linear Interpolation(lerp) equation}{
	The equation of the lines between data points is

	\[
		y = \frac{y_{i+1} - y_i}{x_{i+1} - x_i}(x-x_i) + y_i
		.\]
}
\thm{Error due to linear interpolation}{
	Let $f$ be a continuous and differentiable on $[a,b]$. We define the error $z(x)$ to be
	\[
		|z(x)| \leq \frac{(b-a)^2 }{8 }\sup_{a\leq x \leq b}\lt|f''(x)\rt|
		.\]
}

\section{Polynomial Interpolation}

\subsection{Lagrange Polynomials}

Really nice video \href{https://www.youtube.com/watch?v=bzp_q7NDdd4}{here} explaining Lagrange polynomials.


\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				legend pos=outer north east,
				axis lines = box,
				xlabel = $x$,
				ylabel = $f(x)$,
				axis x line=bottom,
				axis y line=left,
				xmin=0,xmax=5.5,
			]

			\addplot[
				only marks,
				color=red,
				mark=*,
			]
			coordinates {
					(0,0)(1,2)(2,3)(3,1)(4,3)(5,3.5)
				};

			\addplot [
				domain=0:5,
				samples=100,
				color=blue,
			]
			{-0.17916*x^5+(13/6)*x^4+(-425/48)*x^3+(163/12)*x^2+(-283/60)*x};
			% \addlegendentry{$-\frac{43}{240}x^5 + \frac{13}{6}x^4 - \frac{425}{48}x^3 + \frac{163 }{12}x^2 - \frac{283}{60}x$}
		\end{axis}
	\end{tikzpicture}
\end{figure}


\thm{Lagrange polynomial equation}{
	Consider a set of $n$ points $(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)$. The Lagrange polynomial for this set of data is
	\[
		L(x) = \sum_{k=0}^{n} y_k \ell_k(x)
		.\]

	where
	\[
		\ell_k(x) = \prod_{\substack{i=1\\i\neq k}}^{n}\frac{x-x_i }{x_k-x_i}
		.\]
}

\subsubsection{Case of equidistant points}

If the set of $x_i$ are equidistant from each other with a distance of $h=x_{i+1}-x_i$, then we can represent any point as $x_k = x_0 + kh$ where $k\in\mathbb{N}$ and any number $x = x_0 + sh$ where $s\in\mathbb{R}$. We can rewrite the formula as
\[
	Q(s) = \sum_{k=0}^{n} \ell_k(s)f(x_k)
	.\]
where
\[
	\ell_k(s) = \prod_{\substack{j=0\\k\neq k}}^n\frac{s-j}{k-j}
	.\]

by substitution
\[
	s = \frac{x-x_0}{h}
	.\]

\subsubsection{Existence}

\begin{myproof}
	$P(x)$ belongs to the vectorial space of polynomial of degree of, at most, $n$. Now, we must fins a basis for this vectorial space. Find the polynomial $\ell_k$ of degree $\leq n$ such that
	\[
		\ell_k(x_i) = \delta_{ki} = \begin{cases}
			1 & \text{if }i=k     \\
			0 & \text{if }i\neq k
		\end{cases}
		.\]
	Then, $\ell_k(x) = \lambda(x-x_0)\dots(x-x_{k-1})(x-x_{k+1})\dots(x-x_n)$
	where
	\[
		\lambda = \frac{1}{(x_k-x_0)\dots(x_k-x_{k-1})(x_k-x_{k+1})\dots(x_k-x_n)}
		.\]
	The $(n+1)$ polynomials $\ell_k(x)$ for a system of generators in the vectorial space of polynomials of degree at most $n$.

	\[
		\lambda_0\ell_0(x) + \lambda_1\ell_1(x) + \dots + \lambda_k\ell_k(x) + \dots + \lambda_n\ell_n(x) = 0
		.\]

	for $x=x_k$
	\begin{align*}
		\lambda_0\ell_0(x_k) + \lambda_1\ell_1(x_k) + \dots + \lambda_k\ell_k(x_k) + \dots + \lambda_n\ell_n(x_k) & = 0 \\
		0+0+\dots+\lambda_k1+\dots+0                                                                              & =0
		\lambda_k                                                                                                 & = 0
		.\end{align*}
	$\therefore$ the set of $\ell_k$ for a basis in the vector space $\Rightarrow$ there has to exist a polynomial passing through the given set of points.

\end{myproof}


\subsubsection{Uniqueness}

\begin{myproof}
	Let $P$ and $Q$ be 2 Lagrange polynomials of degrees $\leq n\Big/P(x_i)=Q(x_i)=f(x_i)\quad\forall i = 0,1,\dots,n$.\\
	Let
	\[
		\begin{rcases}
			R=P-Q \text{ of degree }\leq n\\
			R=0 \; (n+1) \text{ times}
		\end{rcases}R\equiv0\Rightarrow P=Q\;\forall x
		.\]
\end{myproof}

\subsection{Newton Polynomial}

\dfn{Newton Polynomial equation}{
	Consider a set of $n$ points $(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)$. The Newton polynomial for this set of data is
	\[
		p_n(x) = \underbrace{a_0}_{A_0} + \underbrace{a_1(x-x_0)}_{A_1} + \underbrace{a_2(x-x_0)(x-x_1)}_{A_2} + \dots + \underbrace{a_n \prod_{i=0}^{n-1}(x-x_i)}_{A_n}
		.\]
	where
	\[
		a_i = f[x_0,x_1,\dots,x_i]
		.\]
	Here $f[\dots]$ is the divided difference of the inputted data.
}

\dfn{Backwards formula}{
\[
	P_n(x) = f_n + A_1 + A_2 + \dots+ A_n
	.\]

where
\[
	A_i = f[x_n,x_{n-1},\dots,x_{n-i}]\prod_{j=n-i+1}^{n}(x-x_j)
	.\]
}

The divided difference has 2 formulas, the recurrence formula
\[
	f[x_0,x_1,\dots,x_{n+1}] = \frac{f[x_1,x_2,\dots,x_{n+1}]-f[x_0,x_1,\dots,x_{n}]}{x_{n+1}-x_0}
	.\]

and a general formula
\[
	f[x_0,x_1,\dots,x_n] = \sum_{i=1}^{n}\frac{y_i }{\prod_{\substack{k=0\\k\neq i}}^{n} (x_i - x_k)}
	.\]
Now forget you ever saw those cause there is an easier method to finding the divided difference.

\subsubsection{Divided Difference Table}
\[
	\begin{array}{cccccc}
		x_0 & y_0                                                                                              \\
		    &     & \frac{y_1-y_0}{x_1-x_0}=f[x_0,x_1]                                                         \\
		x_1 & y_1 &                                    & \frac{f[x_1,x_2]-f[x_0,x_1]}{x_2-x_0}                 \\
		    &     & \frac{y_2-y_1}{x_2-x_1}=f[x_1,x_2] &                                       & \dots         \\
		x_2 & y_2 &                                    & \frac{f[x_2,x_3]-f[x_1,x_2]}{x_3-x_1} &       & \dots \\
		    &     & \frac{y_3-y_2}{x_3-x_2}=f[x_2,x_3] &                                       & \dots         \\
		x_3 & y_3 &                                    & \frac{f[x_3,x_4]-f[x_2,x_3]}{x_4-x_2}                 \\
		    &     & \frac{y_4-y_3}{x_4-x_3}=f[x_3,x_4]                                                         \\
		x_4 & y_4
	\end{array}
\]
After we have constructed the table we can find the divided difference we want by looking at the top diagonal

\[
	\begin{array}{cccccc}
		x_0 & y_0                                                                             \\
		    &     & f[x_0,x_1]                                                                \\
		x_1 & y_1 &            & f[x_0,x_1,x_2]                                               \\
		    &     & \dots      &                & f[x_0,x_1,x_2,x_3]                          \\
		x_2 & y_2 &            & \dots          &                    & f[x_0,x_1,x_2,x_3,x_4] \\
		    &     & \dots      &                & \dots                                       \\
		x_3 & y_3 &            & \dots                                                        \\
		    &     & \dots                                                                     \\
		x_4 & y_4
	\end{array}
\]


\subsubsection{Case of equidistant points}
Bla bla bla the formula becomes

\[
	P(t) = a_0 + a_1(t-0) + a_2(t-0)(t-1) + \dots + a_n \prod_{i=0}^{n-1}(t-i)
	.\]

where in this case
\[
	a_k = \frac{\nabla^k[y](x_k)}{k!}
	.\]

and
\[
	x = x_0 +th
	.\]

where $\nabla^k[y]$ is the discrete difference.

\[
	\nabla[y](x_i) = y(x_i+h)-y(x_i)
	.\]

and the backwards formula is
\[
	P(t) = f_n + A_1 + A_2 + \dots + A_n
	.\]

where
\[
	A_i = \frac{\bar{\nabla}^if_n}{i!}\prod_{j=n-i+1}^n (t-j)
	.\]

\dfn{Discrete Difference}{
	Forward discrete difference:
	\begin{align*}
		\nabla[y](x_i)   & = y(x_i+h) - y(x_i)                    \\
		\nabla^2[y](x_i) & = \nabla[y](x_i + h) - \nabla [y](x_i) \\
		                 & = y(x_i+2h)-2y(x_i+h)+y(x_i)           \\
		\nabla^k[y](x_i) & = \nabla\lt(\nabla^{k-1}[y](x_i)\rt)
	\end{align*}


	Backwards discrete difference:
	\begin{align*}
		\bar{\nabla}[y](x_i)   & = y(x_i) - y(x_i - h)                            \\
		\bar{\nabla}^k[y](x_i) & = \bar{\nabla}\lt(\bar{\nabla}^{k-1}[y](x_i)\rt)
	\end{align*}
}
\[
	\begin{array}{cccccc}
		x_0 & y_0                                                                           \\
		    &     & \nabla[y](x_i)                                                          \\
		x_1 & y_1 &                & \nabla^2[y](x_i)                                       \\
		    &     & \dots          &                  & \nabla^3[y](x_i)                    \\
		x_2 & y_2 &                & \dots            &                  & \nabla^4[y](x_i) \\
		    &     & \dots          &                  & \dots                               \\
		x_3 & y_3 &                & \dots                                                  \\
		    &     & \dots                                                                   \\
		x_4 & y_4
	\end{array}
\]

\subsection{Error due to polynomial interpolation}

Let $f(x)$ be of class $C^{n+1} \quad \forall x \in [a,b]$ and let the polynomial $P(x)$ interpolate it. \\

The error function is bounded by
\[
	|\text{Error}| = |f(x) - P(x)| \leq \frac{\lt| \prod_{i=0}^n (x-x_i) \rt|}{(n+1)!} \sup_{x\in[a,b]} |f^{(n+1)}(x)|
	.\]

\subsection{Hermite Interpolation}

\dfn{Hermite interpolation formula}{
	Consider $(n+1)$ sets of point $(x_i,y_i,y'_i)$ representing $f(x)$ ($y_i = f(x_i)$ and $y_i' = f'(x_i)$), the hermite polynomial $P(x)$ interpolates $f(x)$ such that $P'(x) = f'(x)$.

	\[
		P(x) = \sum_{i=0}^n h_i(x)y_i + \sum_{i=0}^{n}k_i(x)y_i'
		.\]

	where
	\begin{align*}
		h_i(x)    & =\lt(1-2(x-x_i)\ell_i'(x_i)\rt)\ell^2_i(x) \\
		k_i(x)    & =(x-x_i)\ell^2_i(x)                        \\
		\ell_i(x) & = \prod_{\substack{j=0                     \\j\neq i}}^n \frac{x-x_j}{x_i-x_j}
	\end{align*}
}

\thm{Error due to Hermite interpolation}{
\[
	|\text{Error}| = |f(x) - P(x)| \leq \frac{\lt| \prod_{i=0}^n (x-x_i)^2 \rt|}{(2n+2)!} \sup_{x\in[a,b]} |f^{(2n+2)}(x)|
	.\]
}

\subsubsection{Existence}

\begin{myproof}

	\[
		P(x) = \sum_{i=0}^n h_i(x)y_i + \sum_{i=0}^{n}k_i(x)y_i'
		.\]

	where
	\begin{align*}
		h_i(x)    & =\lt(1-2(x-x_i)\ell_i'(x_i)\rt)\ell^2_i(x) \\
		k_i(x)    & =(x-x_i)\ell^2_i(x)                        \\
		\ell_i(x) & = \prod_{\substack{j=0                     \\j\neq i}}^n \frac{x-x_j}{x_i-x_j}
	\end{align*}

	Let $i\neq j$.
	\begin{align*}
		k_i(x_j) & = (x_j-x_i)\ell_i^2(x_j)=0 \\
		k_i(x_i) & = (x_i-x_i)\ell_i^2(x_i)=0
	\end{align*}
	and
	\begin{align*}
		h_i(x_j) & = (1-2(x_j-x_i)\ell_i'(x_i))\ell_i^2(x_j)=0 \\
		h_i(x_j) & = (1-2(x_i-x_i)\ell_i'(x_i))\ell_i^2(x_i)=1
	\end{align*}
	We conclude that $P(x_i) = f(x_i)$\\

	Now we have to prove that $P'(x_i) = f'(x_i)$
	\begin{align*}
		h_i'(x) & = -2\ell_i'(x_i)\ell_i^2(x)+2(1-2(x-x_i)\ell_i'(x_i))\ell_i(x)\ell_i'(x) \\
		k_i'(x) & = \ell^2_i(x) + 2(x-x_i)\ell_i(x)\ell_i'(x)
	\end{align*}

	\begin{align*}
		h_i'(x_j) & = -2\ell_i'(x_i)\ell_i^2(x_j)+2(1-2(x_j-x_i)\ell_i'(x_i))\ell_i(x_j)\ell_i'(x_j) = 0 \\
		h_i'(x_i) & = -2\ell_i'(x_i)\ell_i^2(x_i)+2(1-2(x_i-x_i)\ell_i'(x_i))\ell_i(x_i)\ell_i'(x_i) =0  \\
	\end{align*}

	\begin{align*}
		k_i'(x_j) & = \ell^2_i(x-j) + 2(x_j-x_i)\ell_i(x_j)\ell_i'(x_j) = 0 \\
		k_i'(x_j) & = \ell^2_i(x-i) + 2(x_i-x_i)\ell_i(x_i)\ell_i'(x_i) = 1 \\
	\end{align*}
	$\therefore P'(x_i) = f'(x_i)$
\end{myproof}

\subsubsection{Uniqueness}

\begin{myproof}
	Suppose that there exists 2 polynomials $P$ and $Q$ of degree $n\leq 2n+1$ such that $P(x_i)=Q(x_i)=f(x_i)$ and $P'(x_i)=Q'(x_i)=f'(x_i)\;\forall i = 0,1,\dots,n$.\\
	Let $R(x)=P(x)-Q(x)$.\\
	$R=0\;(n+1)$ times $\Rightarrow$ according to Rolle's theorem $\exists\,n$ points $\neq x_i\Big/R'=0$\\
	$R'=0\;n$ times as a consequence of Rolle's theorem then
	\[
		\begin{rcases}
			R'(x)=0\;(2n+1)\text{ times}\\
			R'(x)\text{ is of degree }2n
		\end{rcases}
		R'(x)=0 \;\forall x
		.\]

	\[
		R'(x)=0\Rightarrow R(x)=\text{cnst}\quad\text{and}\quad R(x_i)=P(x_i)-Q(x_i)=0 \Rightarrow \text{cnst } = 0
		.\]

	\[
		R(x) = P(x)-Q(x)=0 \;\forall x
		.\]
	$\therefore P(x) = Q(x)$
\end{myproof}


\chapter{Finding $f(x)=0$}

We will assume that every function is defined in the interval $I = [a,b]$ and that every $x_0\in I$

\section{Bisection Method}

Suppose that $f$ is a continuous and monotone function on the domain $I = [a,b]$ such that $f(a)f(b)<0\Rightarrow \exists r \in]a,b[:\;f(r)=0$.\\

At each step in the algorithm, in an iteration we let $c = (a+b)/2$, then we check the value of $f(c)$, if it is 0 then we are done.\\
However when it is not, then we define a new interval such that

\[
	I = \begin{cases}
		[a,c] & \text{if }f(c)f(a)<0 \\
		[c,b] & \text{if }f(c)f(b)<0
	\end{cases}
	.\]

We repeat this step until the length of the interval reaches a certain number (for example $|b-a|<10^{-5}$), at this point we stop and the best guess for the root would be $(a+b)/2$

\subsubsection{Error of the Bisection Method}

After $n$ iterations, the error of the approximated root would be
\[
	\text{Error} \leq \frac{|b-a|}{2^{n+1}}
	.\]

\section{Lagrange Method}

Suppose that $f$ is a continuous and monotone function on the domain $I = [a,b]$ such that $f(a)f(b)<0\Rightarrow \exists r \in]a,b[:\;f(r)=0$.\\

The starting value of $x_0$ depends on the value of $f$
\[
	x_0 = \begin{cases}
		a & \text{if }f(a)f''(a)<0 \\
		b & \text{if }f(b)f''(b)<0
	\end{cases}
	.\]

then we can find a new guess $x$ depending on the value of $x_0$
\begin{itemize}
	\ii if $x_0 = a$

	\[
		x_1 = x_0 - \frac{b-x_0}{f(b)-f(x_0)}f(x_0)
		.\]
	\ii if $x_0 = b$
	\[
		x_1 = x_0-\frac{a-x_0}{f(a)-f(x_0)}f(x_0)
		.\]
\end{itemize}

\subsubsection{Error from Lagrange Method}
For the first iteration
\[
	\text{Error} \leq \sup_{x\in[a,b]}|f''(x)|\frac{(b-a)^2}{8}
	.\]
For the second iteration
\[
	M_2 = \sup_{x\in[a,b]}|f''(x)|
	.\]
\begin{itemize}
	\ii if $x_0 = a$
	\[
		\text{Error} \leq \frac{M_2}{8}\lt|\frac{(b-x_0)^3}{f(b)-f(x_0)}\rt|
		.\]
	\ii if $x_0 = b$
	\[
		\text{Error} \leq \frac{M_2}{8}\lt|\frac{(a-x_0)^3}{f(a)-f(x_0)}\rt|
		.\]
\end{itemize}

\section{Newton Method}

Suppose that $f$ is a continuous and monotone function on the domain $I = [a,b]$ such that $f(a)f(b)<0\Rightarrow \exists r \in]a,b[:\;f(r)=0$.\\

The starting value of $x_0$ depends on the value of $f$
\[
	x_0 = \begin{cases}
		a & \text{if }f(a)f''(a)<0 \\
		b & \text{if }f(b)f''(b)<0
	\end{cases}
	.\]

Then the new guess for the root would be
\[
	x_1 = x_0 - \frac{f(x_0)}{f'(x_0)}
	.\]

\subsection{Improved Newton Method}
To improve the method we first let $\eta = b-a$, and we define condition
\[
	\frac{\eta M_2}{2|f'(x_0)|}<1
	.\]
if the condition is not satisfied we need to choose another interval $[a_1,b_1]\subset I$ where $f(a_1)f(b_1)<0$

\subsubsection{Error due to Newton Method}

For one iteration
\[
	\text{Error} = \leq \frac{\eta^2 M_2}{2|f'(x_0)|} \quad\text{where}\quad M_2 = \sup_{x\in[x_0-\eta,x_0+\eta]} |f''(x)|
	.\]

\section{Fixed Point Iteration Method}
If a function can be converted to the form $x=g(x)$ along with the sequence $x_{n+1} = g(x_n)$ with initial guess $x_0$, then it is called a fixed point scheme.

The scheme converges if
\begin{itemize}
	\ii $\forall x \in [a,b]:\; g(x)\in[a,b]$
	\ii $g$ is strictly contracting meaning that $\exists \varepsilon \in \RR\; 0\leq \varepsilon < 1$
	\[
		\forall x,y \in[a,b],\; |g(x)-g(y)|\leq \varepsilon|x-y|
		.\]
\end{itemize}
then $\forall x_0$ the sequence converges to $l\in[a,b]$

\nt{
	\[
		\sup_{x\in[a,b]}|g'(x)| = L<1\Rightarrow g(x)\text{ is strictly contracting}
		.\]
}

\nt{
	Let $l$ be the solution to $g(l)=l$
	\begin{itemize}
		\ii If $|g'(l)| <1$ then there exists an interval $I$ containing $l$ for which the sequence converges to $l$
		\ii If $|g'(l)| >1$ then the sequence diverges
	\end{itemize}
}

\section{Order of Convergence}
Order of convergence (Rate of convergence) tells us how the error decreases between 2 iterations. The order of convergence $p$ of a sequence is defined to be
\[
	\lim_{n\to+\infty}\lt|\frac{x_{n+1}-l}{(x_n-l)}\rt|\in \RR^*_+
	.\]

\nt{
	The order of convergence of
	\begin{itemize}
		\ii Lagrange Method
		\[
			g'(l) = \frac{(b-l)^2}{2f(b)}f''(c)
			.\]
		If $f''(c)\neq0$ then $g'(l)\neq0$ then the order is 1.
		\ii Newton method, if $g'(l)=0$ then the order is at least 2.
	\end{itemize}
}

\nt{
	We stop the iteration method when
	\begin{itemize}
		\ii First case $g'(x)<0$, then we stop iteration when
		\[
			|x_{n+1}-r|<\varepsilon
			.\]
		\ii Second case $g'(x)>0$, then we stop iteration when
		\[
			|f(x_n)|<\eta
			.\]
		where
		\[
			\eta = \varepsilon\inf|f'(x)|
			.\]
	\end{itemize}
}

\section{Polynomial Shenanigans}
\subsection{Roots of $x^3 + px + q = 0$}

Let $y_1(x) = x^3 + px$ and $y_2(x)=-q$

\begin{itemize}
	\ii $p\geq 0\Rightarrow \exists\,1$ root
	\ii $p<0$ then we have 3 separate cases
	\[
		27q^2 + 4p^3 \begin{cases}
			=0 & \text{we have 2 separate real roots (one double and one single)} \\
			>0 & \text{we have one real root}                                     \\
			<0 & \text{we have 3 separate real roots}
		\end{cases}
		.\]
\end{itemize}

\subsection{Roots of $x^3+ax^2 + bx +c = 0$}

If we replace $x$ with $X+h$ where $h = -\frac{a}{3}$, we can get the cubic in the form
\[
	X^3 + PX + Q = 0
	.\]

where
\begin{align*}
	P & = -\frac{a^2}{3}+b                 \\
	Q & = \frac{2a^3}{27} - \frac{ab}{3}+c
\end{align*}

\subsection{Roots of $x^4+ax^3+bx^2+cx+d=0$}

If we replace $x$ with $X+h$ where $h = -\frac{a}{4}$, we can get the quartic in the form
\[
	X^4 + PX^2 + QX + R = 0
	.\]

where
\begin{align*}
	P & = -\frac{3a^2}{8}+b                   \\
	Q & = \frac{a^3}{8} -\frac{ab}{2} + c     \\
	R & = -\frac{3a^4}{256} -\frac{ac}{4} + d
\end{align*}

Let the circle $C$ be the circle of radius $\displaystyle\lt(-\frac{Q}{2},\frac{1-P}{2}\rt)$ and of radius $\displaystyle\sqrt{\lt(\frac{P-1}{2}\rt)^2 + \frac{Q^2}{4} - R}$.\\

The roots of the polynomial $X^4 + PX^2 + QX + R = 0$ are the intersection of the circle $C$ and the parabola $Y=X^2$



\end{document}
